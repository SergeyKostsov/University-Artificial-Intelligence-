{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Добейтесь точности распознавания жанров музыки не менее 79% стабильно на последних эпохах обучения. \n",
        "\n",
        "Используйте разбивку 900 записей на обучающую выборку и 100 на проверочную."
      ],
      "metadata": {
        "id": "6ysC4ULDFomY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFxWn9D0K3Zt"
      },
      "source": [
        "### Классификация музыкальных жанров\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztE5w_alL0q0"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import os # Работа с папками и файлами\n",
        "import librosa # Параметризация аудио\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import concatenate, Input, Dense, Dropout, BatchNormalization, Flatten, Conv1D, Conv2D, LSTM\n",
        "from sklearn.model_selection import train_test_split # Разбиение на обучающую и проверочную выборку\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Z9dv4oXyGI",
        "outputId": "dd714379-0234-45aa-8537-bb7fd0ba4456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhzkhPPMXycX",
        "outputId": "00fc39ed-a654-410c-f479-b71d424611c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace genres/blues/blues.00000.au? [y]es, [n]o, [A]ll, [N]one, [r]ename: blues  classical  country  disco  hiphop  jazz\tmetal  pop  reggae  rock\n",
            "blues.00000.au\tblues.00020.au\tblues.00040.au\tblues.00060.au\tblues.00080.au\n",
            "blues.00001.au\tblues.00021.au\tblues.00041.au\tblues.00061.au\tblues.00081.au\n",
            "blues.00002.au\tblues.00022.au\tblues.00042.au\tblues.00062.au\tblues.00082.au\n",
            "blues.00003.au\tblues.00023.au\tblues.00043.au\tblues.00063.au\tblues.00083.au\n",
            "blues.00004.au\tblues.00024.au\tblues.00044.au\tblues.00064.au\tblues.00084.au\n",
            "blues.00005.au\tblues.00025.au\tblues.00045.au\tblues.00065.au\tblues.00085.au\n",
            "blues.00006.au\tblues.00026.au\tblues.00046.au\tblues.00066.au\tblues.00086.au\n",
            "blues.00007.au\tblues.00027.au\tblues.00047.au\tblues.00067.au\tblues.00087.au\n",
            "blues.00008.au\tblues.00028.au\tblues.00048.au\tblues.00068.au\tblues.00088.au\n",
            "blues.00009.au\tblues.00029.au\tblues.00049.au\tblues.00069.au\tblues.00089.au\n",
            "blues.00010.au\tblues.00030.au\tblues.00050.au\tblues.00070.au\tblues.00090.au\n",
            "blues.00011.au\tblues.00031.au\tblues.00051.au\tblues.00071.au\tblues.00091.au\n",
            "blues.00012.au\tblues.00032.au\tblues.00052.au\tblues.00072.au\tblues.00092.au\n",
            "blues.00013.au\tblues.00033.au\tblues.00053.au\tblues.00073.au\tblues.00093.au\n",
            "blues.00014.au\tblues.00034.au\tblues.00054.au\tblues.00074.au\tblues.00094.au\n",
            "blues.00015.au\tblues.00035.au\tblues.00055.au\tblues.00075.au\tblues.00095.au\n",
            "blues.00016.au\tblues.00036.au\tblues.00056.au\tblues.00076.au\tblues.00096.au\n",
            "blues.00017.au\tblues.00037.au\tblues.00057.au\tblues.00077.au\tblues.00097.au\n",
            "blues.00018.au\tblues.00038.au\tblues.00058.au\tblues.00078.au\tblues.00098.au\n",
            "blues.00019.au\tblues.00039.au\tblues.00059.au\tblues.00079.au\tblues.00099.au\n"
          ]
        }
      ],
      "source": [
        "!unzip -q '/content/drive/My Drive/Базы/genres.zip' # распаковываем архив на google диске на локальный диск google colaboratory \n",
        "\n",
        "genres = os.listdir('genres') # получаем список папок в распакованной папке\n",
        "\n",
        "# Проверяем выгруженные папки\n",
        "!ls genres \n",
        "# И одну из папок\n",
        "!ls genres/blues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw27TQD1ZTNr"
      },
      "outputs": [],
      "source": [
        "# Функция параметризации аудио\n",
        "def get_features(y, sr):\n",
        "  # Получаем различные параметры аудио\n",
        "  chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr) # Частота цветности (по умолчанию 12 баков цветности)\n",
        "  mfcc = librosa.feature.mfcc(y=y, sr=sr) # Мел кепстральные коэффициенты (по умолчанию 20)\n",
        "\n",
        "  rmse = np.mean(librosa.feature.rms(y=y)) # Среднеквадратичная амплитуда\n",
        "  spec_cent = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr)) # Среднее спектрального центроида\n",
        "  spec_bw = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr)) # Среднее ширины полосы частот\n",
        "  rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr)) # Среднее спектрального спада частоты\n",
        "  zcr = np.mean(librosa.feature.zero_crossing_rate(y)) # Среднее частота пересечения нуля звукового временного ряда\n",
        "  \n",
        "\n",
        "  # Добавляем все параметры в один список\n",
        "  out = []\n",
        "  out.append(rmse) # добавляем среднеквадратичную амплитуду\n",
        "  out.append(spec_cent) # добавляем спектральный центроид\n",
        "  out.append(spec_bw) # добавляем ширину полосы частот\n",
        "  out.append(rolloff) # добавляем спектральный спад частоты\n",
        "  out.append(zcr) # добавляем пересечение нуля\n",
        " \n",
        "\n",
        "  # Добавляем среднее всех Мел спектральных коэффициентов (20 коэффициентов)\n",
        "  for e in mfcc:\n",
        "    out.append(np.mean(e))\n",
        "  \n",
        "  # Добавляем среднее всех частот цветности (12 коэффициентов)\n",
        "  for e in chroma_stft:\n",
        "    out.append(np.mean(e))\n",
        "  \n",
        "  # Возвращаем получившийся список размерностью (37,) \n",
        "  return out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time # Подключаем модуль time для подсчёта времени на обработку одного жанра\n",
        "\n",
        "# Формируем обучающую выборку\n",
        "# Создаём пустые листы\n",
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "# Запоминаем время старта формирования выборки\n",
        "curr_time = time.time()\n",
        "\n",
        "# Проходим по всем жарнам\n",
        "for i in range(len(genres)):\n",
        "  g = genres[i] # Берём текущий жанр\n",
        "  # Проходим по файлам папки, соответствующей текущему жанру\n",
        "  for filename in os.listdir(f'./genres/{g}'):\n",
        "    # Получаем имя песни\n",
        "    songname = f'./genres/{g}/{filename}'\n",
        "    # Загружаем в y аудиосигнал\n",
        "    # Используем первые 30 секунд аудио\n",
        "    y, sr = librosa.load(songname, mono=True, duration=30) # y - массив данных временного ряда аудио, sr - частота дискретизации временного ряда\n",
        "    # Превращаем сигнал в параметризованные данные\n",
        "    out = get_features(y, sr)\n",
        "    \n",
        "    \n",
        "    # Добавляем строку в X_train\n",
        "    X_train.append(out)\n",
        "    # Добавляем в Y_train номер жанра в формате ohe\n",
        "    Y_train.append(to_categorical(i, len(genres)))\n",
        "\n",
        "  # Выводим информацию о готовности обработки базы\n",
        "  print(\"Жанр \", g, \" готов -> \", round(time.time() - curr_time), \"c\", sep=\"\")\n",
        "  curr_time = time.time()\n",
        "\n",
        "# Превращаем обучающую выборку на numpy массивы\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuOks8P4TKto",
        "outputId": "c7c3d56b-69b3-4a18-d5b0-bcf5a7685cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Жанр country готов -> 51c\n",
            "Жанр pop готов -> 49c\n",
            "Жанр reggae готов -> 51c\n",
            "Жанр blues готов -> 50c\n",
            "Жанр disco готов -> 49c\n",
            "Жанр jazz готов -> 49c\n",
            "Жанр classical готов -> 50c\n",
            "Жанр rock готов -> 45c\n",
            "Жанр hiphop готов -> 49c\n",
            "Жанр metal готов -> 49c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NjzWiPUiTxi"
      },
      "outputs": [],
      "source": [
        "# Создаем backup обучающей выборки\n",
        "X_train_backup = X_train.copy()\n",
        "Y_train_backup = Y_train.copy()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train[5]))\n",
        "print(len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkVcMbrNcUx2",
        "outputId": "ddc7a457-a5b5-4021-8b15-1b2b2b44b324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37\n",
            "991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[77]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HPyI5CCSWoa",
        "outputId": "e2ae6e47-3126-4f9e-91af-031bf5cc25c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8.71645361e-02,  1.32783139e+03,  1.63297451e+03,  2.75602500e+03,\n",
              "        6.10873101e-02, -2.17141983e+02,  1.36159256e+02, -1.03507509e+01,\n",
              "        5.13835869e+01,  2.61628222e+00,  1.51244001e+01, -6.66066468e-01,\n",
              "        1.22880259e+01, -6.22800922e+00,  7.79273224e+00, -5.41524839e+00,\n",
              "        3.62371922e+00, -2.80927062e+00, -3.51482153e-01, -5.53418040e-01,\n",
              "        3.70173484e-01, -2.24874830e+00, -2.49541402e+00,  4.18859339e+00,\n",
              "        3.42443496e-01,  2.06485897e-01,  3.75383794e-01,  5.76249003e-01,\n",
              "        3.35114568e-01,  2.69194245e-01,  2.25021616e-01,  3.35900366e-01,\n",
              "        3.39530081e-01,  3.79021823e-01,  5.80321133e-01,  3.17055941e-01,\n",
              "        2.87962735e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn4JdUjaitIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c742441-7710-44a0-c2d2-fd1b07d166f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
            " 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
            " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
            " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
            " 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8 8\n",
            " 8 8 8 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
            " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9\n",
            " 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9]\n"
          ]
        }
      ],
      "source": [
        "# Выводим номера классов, для проверки правильности заполнения\n",
        "# И номера классов идут последовательно крупными блоками\n",
        "y_train_class = np.argmax(Y_train, axis=1)\n",
        "print(y_train_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMJhJZnXitXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e4febb-261b-4e33-b49f-9a3eaccfcb08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(991, 37)\n",
            "(991, 10)\n",
            "(991,)\n"
          ]
        }
      ],
      "source": [
        "# Выводим размеры обучающей выборки\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(y_train_class.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD7dSGnejbKv"
      },
      "outputs": [],
      "source": [
        "# Создаём scaler экземпляр класса StandardScaler() для нормировки данных\n",
        "scaler = StandardScaler()\n",
        "# Нормируем X_train\n",
        "X_train = scaler.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE4EqECHjug_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0a1a50-4358-4af8-8c87-04fa66e3aaad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.05660075e-01  2.56097268e-01  8.92895517e-01  5.15233377e-01\n",
            " -3.95311616e-01  4.31105650e-01 -4.88212104e-01  7.60898307e-01\n",
            " -3.46326430e-01  1.22302514e+00 -2.46614564e-01  4.96785673e-01\n",
            " -1.43042274e+00  5.48799758e-01 -1.21568558e+00 -3.28471330e-01\n",
            " -2.37109617e-01  8.59002736e-01 -1.70372827e+00 -1.00134792e-01\n",
            " -1.24367181e+00 -1.31451484e+00 -1.59583965e+00 -2.19719408e+00\n",
            " -1.66445097e+00  6.06977099e-01  6.33920061e-01  2.40765245e-01\n",
            " -3.81026925e-01  2.11625574e-01 -6.04393269e-01 -1.02283421e+00\n",
            " -6.96794032e-01 -2.08100877e-03  1.26617246e+00  6.97025297e-01\n",
            "  3.17788628e-01]\n"
          ]
        }
      ],
      "source": [
        "#Проверяем, что X_train нормировался\n",
        "print(X_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AB4wa1uj0ZJ"
      },
      "outputs": [],
      "source": [
        "# Разделяем выборку на обучающую и проверочную\n",
        "# Для проверочной используем 10 % примеров, так как база маленькая\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, y_train_class, test_size = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xfAUym7j0hg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d941a42c-be5c-48b7-d5d7-bb5dcf443809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(891, 37)\n",
            "(891,)\n",
            "(100, 37)\n",
            "(100,)\n"
          ]
        }
      ],
      "source": [
        "# Выводим размеры обучающей и проверочной выборок для проверки\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqfyRleykjDe"
      },
      "source": [
        "### Создаем нейронку"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "chkpt = ModelCheckpoint('model.h5', \n",
        "                        monitor='val_accuracy', \n",
        "                        verbose=1, \n",
        "                        save_best_only=True, \n",
        "                        mode='auto')\n",
        "lrPlato = ReduceLROnPlateau(monitor='val_mae', \n",
        "                            factor=0.2, \n",
        "                            patience=5, \n",
        "                            verbose=0, \n",
        "                            mode='auto', \n",
        "                            min_delta=0.0001, \n",
        "                            cooldown=20, \n",
        "                            min_lr=1e-5) "
      ],
      "metadata": {
        "id": "kZ49ebhH5VbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO6wfxgRknhH"
      },
      "outputs": [],
      "source": [
        "# Указываем, какие индексы данных во входных векторах брать для обучения\n",
        "# Делаем это для того, чтобы можно было экспериментировать\n",
        "# И обучать не на всех колонках данных, а на части\n",
        "indexes = range(0,37)\n",
        "\n",
        "# Создаем полносвязную сеть\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='elu', input_shape=(len(indexes),)))\n",
        "model.add(Dense(128,activation='elu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(64,activation='elu'))\n",
        "model.add(Dense(32,activation='elu'))\n",
        "model.add(BatchNormalization())\n",
        "# В выходном слое количество нейронов равно количеству классов(жанров) и активация softmax\n",
        "model.add(Dense(len(genres), activation = 'softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Компилируем сеть\n",
        "model.compile(optimizer=RMSprop(lr=1e-6),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpxTRb8ds5tz",
        "outputId": "aa61804f-388d-44b8-86c8-ee61d35be6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c_BEQp6mZmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2454ac8-7208-45ad-ca31-21c02dbd70d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "19/28 [===================>..........] - ETA: 0s - loss: 0.0055 - accuracy: 0.9967     \n",
            "Epoch 00001: val_accuracy did not improve from 0.80000\n",
            "28/28 [==============================] - 2s 10ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 2.3590 - val_accuracy: 0.8000\n",
            "Epoch 2/10\n",
            "20/28 [====================>.........] - ETA: 0s - loss: 0.0230 - accuracy: 0.9937    \n",
            "Epoch 00002: val_accuracy did not improve from 0.80000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 2.3560 - val_accuracy: 0.8000\n",
            "Epoch 3/10\n",
            "20/28 [====================>.........] - ETA: 0s - loss: 0.0168 - accuracy: 0.9953\n",
            "Epoch 00003: val_accuracy did not improve from 0.80000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0181 - accuracy: 0.9944 - val_loss: 2.3501 - val_accuracy: 0.8000\n",
            "Epoch 4/10\n",
            "21/28 [=====================>........] - ETA: 0s - loss: 0.0342 - accuracy: 0.9911    \n",
            "Epoch 00004: val_accuracy did not improve from 0.80000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 2.3491 - val_accuracy: 0.8000\n",
            "Epoch 5/10\n",
            "18/28 [==================>...........] - ETA: 0s - loss: 0.0207 - accuracy: 0.9948\n",
            "Epoch 00005: val_accuracy did not improve from 0.80000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9933 - val_loss: 2.3441 - val_accuracy: 0.8000\n",
            "Epoch 6/10\n",
            "19/28 [===================>..........] - ETA: 0s - loss: 0.0141 - accuracy: 0.9951\n",
            "Epoch 00006: val_accuracy did not improve from 0.80000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0153 - accuracy: 0.9944 - val_loss: 2.3393 - val_accuracy: 0.8000\n",
            "Epoch 7/10\n",
            "18/28 [==================>...........] - ETA: 0s - loss: 0.0204 - accuracy: 0.9913\n",
            "Epoch 00007: val_accuracy did not improve from 0.80000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.9921 - val_loss: 2.3464 - val_accuracy: 0.8000\n",
            "Epoch 8/10\n",
            "20/28 [====================>.........] - ETA: 0s - loss: 0.0120 - accuracy: 0.9953\n",
            "Epoch 00008: val_accuracy did not improve from 0.80000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 2.3408 - val_accuracy: 0.8000\n",
            "Epoch 9/10\n",
            "16/28 [================>.............] - ETA: 0s - loss: 0.0302 - accuracy: 0.9902\n",
            "Epoch 00009: val_accuracy did not improve from 0.80000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 2.3372 - val_accuracy: 0.8000\n",
            "Epoch 10/10\n",
            "17/28 [=================>............] - ETA: 0s - loss: 0.0232 - accuracy: 0.9945    \n",
            "Epoch 00010: val_accuracy did not improve from 0.80000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 2.3370 - val_accuracy: 0.8000\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train,\n",
        "                    Y_train,\n",
        "                    epochs = 10,\n",
        "                    batch_size = 32,\n",
        "                    validation_data = (X_test, Y_test),\n",
        "                    callbacks = [chkpt])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.save_weights('model.h5')\n",
        "model.load_weights('model.h5')"
      ],
      "metadata": {
        "id": "dw9kPejIeAuS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": " \"Копия блокнота \" \"Нейронные сети для обработки аудио. Классификация жанров (Университет искусственного интеллекта)\" Pro\"",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}